{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab1e3dd-3955-4913-8979-b0694806d672",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e3b7c7d-ffa6-4631-99f6-59a19e432e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "val_df = pd.read_csv('validation_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "plots_dir = os.path.join(os.getcwd(), 'plots')\n",
    "\n",
    "# Display distribution of types\n",
    "# print(\"\\nOriginal distribution of news types:\")\n",
    "# print(train_df['type'].value_counts())\n",
    "# print(\"\\nBinary class distribution (Training set):\")\n",
    "# print(train_df['binary_type'].value_counts())\n",
    "# print(\"\\nBinary class distribution (Validation set):\")\n",
    "# print(val_df['binary_type'].value_counts())\n",
    "# print(\"\\nBinary class distribution (Test set):\")\n",
    "# print(test_df['binary_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979b39d-d389-4764-a888-16ffc2ed0fb7",
   "metadata": {},
   "source": [
    "# Task 1: Implement simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6857f81d-f753-4397-b9a4-a1add922d251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline model performance on validation set:\n",
      "F1 Score: 0.9517\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.96      0.95      0.95        73\n",
      "    reliable       0.83      0.86      0.84        22\n",
      "\n",
      "    accuracy                           0.93        95\n",
      "   macro avg       0.89      0.90      0.90        95\n",
      "weighted avg       0.93      0.93      0.93        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrix with the 10,000 most frequent words and get target labels\n",
    "count_vectorizer = CountVectorizer(max_features=10000)\n",
    "X_train_count = count_vectorizer.fit_transform(train_df['cleaned_content'])\n",
    "X_val_count = count_vectorizer.transform(val_df['cleaned_content'])\n",
    "X_test_count = count_vectorizer.transform(test_df['cleaned_content'])\n",
    "y_train = train_df['binary_type']\n",
    "y_val = val_df['binary_type']\n",
    "y_test = test_df['binary_type']\n",
    "\n",
    "# Calculate class weights to handle imbalance\n",
    "class_weights = {\n",
    "    'fake': 1.0,\n",
    "    'reliable': len(train_df[train_df['binary_type'] == 'fake']) / len(train_df[train_df['binary_type'] == 'reliable'])\n",
    "}\n",
    "\n",
    "# Train logistic regression model with class weights\n",
    "baseline_model = LogisticRegression(max_iter=1000, random_state=42, class_weight=class_weights)\n",
    "baseline_model.fit(X_train_count, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "baseline_val_pred = baseline_model.predict(X_val_count)\n",
    "baseline_val_f1 = f1_score(y_val, baseline_val_pred, pos_label='fake')\n",
    "print(f\"\\nBaseline model performance on validation set:\")\n",
    "print(f\"F1 Score: {baseline_val_f1:.4f}\")\n",
    "print(\"\\nDetailed classification report:\")\n",
    "print(classification_report(y_val, baseline_val_pred))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm_baseline = confusion_matrix(y_val, baseline_val_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_baseline, annot=True, fmt='d', cmap='Blues', xticklabels=['reliable', 'fake'], yticklabels=['reliable', 'fake'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Baseline Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'Part2Task1_baseline_confusion_matrix.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da453f-6c57-47b1-a120-3445d1cd3443",
   "metadata": {},
   "source": [
    "# Task 2: Inclusion of meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a70ade-f59f-47c6-906f-34920a1353c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model with metadata performance on validation set:\n",
      "F1 Score: 0.9733\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      1.00      0.97        73\n",
      "    reliable       1.00      0.82      0.90        22\n",
      "\n",
      "    accuracy                           0.96        95\n",
      "   macro avg       0.97      0.91      0.94        95\n",
      "weighted avg       0.96      0.96      0.96        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode domains\n",
    "domain_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=True)\n",
    "train_domains = domain_encoder.fit_transform(train_df[['domain']])\n",
    "val_domains = domain_encoder.transform(val_df[['domain']])\n",
    "\n",
    "# Combine text features with domain features\n",
    "X_train_with_meta = hstack([X_train_count, train_domains])\n",
    "X_val_with_meta = hstack([X_val_count, val_domains])\n",
    "\n",
    "# Train model with metadata\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=42, class_weight=class_weights)\n",
    "meta_model.fit(X_train_with_meta, y_train)\n",
    "\n",
    "# Evaluate\n",
    "meta_val_pred = meta_model.predict(X_val_with_meta)\n",
    "meta_val_f1 = f1_score(y_val, meta_val_pred, pos_label='fake')\n",
    "print(f\"\\nModel with metadata performance on validation set:\")\n",
    "print(f\"F1 Score: {meta_val_f1:.4f}\")\n",
    "print(\"\\nDetailed classification report:\")\n",
    "print(classification_report(y_val, meta_val_pred))\n",
    "\n",
    "# Create confusion matrix\n",
    "cm_meta = confusion_matrix(y_val, meta_val_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_meta, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['reliable', 'fake'], \n",
    "            yticklabels=['reliable', 'fake'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Model with Metadata')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'Part2Task2_metadata_confusion_matrix.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534b14f-332d-4f01-8a81-706b808f76ca",
   "metadata": {},
   "source": [
    "# Task 3: Scraped articles from assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b442013a-ab13-41d1-900b-f722780b62d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model with BBC data performance on validation set:\n",
      "F1 Score: 0.9379\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.93      0.94        73\n",
      "    reliable       0.78      0.82      0.80        22\n",
      "\n",
      "    accuracy                           0.91        95\n",
      "   macro avg       0.86      0.87      0.87        95\n",
      "weighted avg       0.91      0.91      0.91        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('bbc_articles_content.json', 'r', encoding='utf-8') as f:\n",
    "    bbc_data = json.load(f)\n",
    "bbc_df = pd.DataFrame(bbc_data)\n",
    "# Keep only articles with content\n",
    "bbc_df = bbc_df[bbc_df['text'].str.len() > 0].copy()\n",
    "# Clean the text using the same function from Part 1\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text using regular expressions\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower() # Convert to lowercase\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '<URL>', text) # Replace URLs\n",
    "    text = re.sub(r'\\S+@\\S+', '<EMAIL>', text) # Replace emails\n",
    "    text = re.sub(r'\\d{1,2}/\\d{1,2}/\\d{2,4}', '<DATE>', text) # Replace dates\n",
    "    text = re.sub(r'\\d{1,2}-\\d{1,2}-\\d{2,4}', '<DATE>', text) # Replace numbers\n",
    "    text = re.sub(r'\\b\\d+\\b', '<NUM>', text)\n",
    "    text = re.sub(r'\\s+', ' ', text) # Remove excess whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "bbc_df['cleaned_content'] = bbc_df['text'].apply(clean_text) # Clean BBC content\n",
    "bbc_df['type'] = 'reliable' # Add 'type' column\n",
    "bbc_df['binary_type'] = 'reliable' # Add 'binary_type' column\n",
    "bbc_subset = bbc_df[['cleaned_content', 'type', 'binary_type']].copy() # Select relevant columns for combining with training data\n",
    "combined_train_df = pd.concat([train_df, bbc_subset], ignore_index=True) # Combine BBC data with training data\n",
    "# print(f\"Added {len(bbc_subset)} BBC articles to the training data\")\n",
    "# print(f\"New training data distribution:\")\n",
    "# print(combined_train_df['binary_type'].value_counts())\n",
    "# Create features for combined dataset\n",
    "X_combined_train = count_vectorizer.transform(combined_train_df['cleaned_content'])\n",
    "y_combined_train = combined_train_df['binary_type']\n",
    "# Recalculate class weights\n",
    "combined_class_weights = {\n",
    "    'fake': 1.0,\n",
    "    'reliable': len(combined_train_df[combined_train_df['binary_type'] == 'fake']) / \n",
    "                len(combined_train_df[combined_train_df['binary_type'] == 'reliable'])\n",
    "}\n",
    "# Train model with combined data\n",
    "combined_model = LogisticRegression(max_iter=1000, random_state=42,class_weight=combined_class_weights)\n",
    "combined_model.fit(X_combined_train, y_combined_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "combined_val_pred = combined_model.predict(X_val_count)\n",
    "combined_val_f1 = f1_score(y_val, combined_val_pred, pos_label='fake')\n",
    "print(f\"\\nModel with BBC data performance on validation set:\")\n",
    "print(f\"F1 Score: {combined_val_f1:.4f}\")\n",
    "print(\"\\nDetailed classification report:\")\n",
    "print(classification_report(y_val, combined_val_pred))\n",
    "# Create confusion matrix\n",
    "cm_combined = confusion_matrix(y_val, combined_val_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_combined, annot=True, fmt='d', cmap='Blues', xticklabels=['reliable', 'fake'], yticklabels=['reliable', 'fake'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Model with BBC Data')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'Part2Task3_bbc_confusion_matrix.png'))\n",
    "plt.close()\n",
    "\n",
    "# Compare all models\n",
    "models = ['Baseline', 'With Metadata', 'With BBC Data']\n",
    "f1_scores = [baseline_val_f1, meta_val_f1, combined_val_f1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=models, y=f1_scores)\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, 'Part2Task3_model_comparison.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a7d15-7e60-43f6-81fd-373fd8d54900",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
